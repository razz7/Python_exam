{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import string\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modelling using LDA\n",
    "https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1946</td>\n",
       "      <td>a quarter century ago the congress decided tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1976</td>\n",
       "      <td>mr. speaker, mr. vice president, members of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>tonight, i come not to speak about the \"state ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002</td>\n",
       "      <td>we last met in an hour of shock and suffering....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>madame speaker, mr. vice president, members of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                             speech\n",
       "0  1946  a quarter century ago the congress decided tha...\n",
       "1  1976  mr. speaker, mr. vice president, members of th...\n",
       "2  1990  tonight, i come not to speak about the \"state ...\n",
       "3  2002  we last met in an hour of shock and suffering....\n",
       "4  2009  madame speaker, mr. vice president, members of..."
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We select speeches from 5 historically significant years from corpus\n",
    "data = pd.read_pickle('pickled_data/data_first_clean.pkl')\n",
    "data.drop(['President', 'Party','speech', 'first_clean_tokenized'], axis=1, inplace = True)\n",
    "#rename column for clarity\n",
    "data = data.rename({'first_clean' : 'speech'}, axis=1)\n",
    "\n",
    "years = [1946, 1976, 1990, 2002, 2009]\n",
    "\n",
    "data = data.loc[data['year'].isin(years)]\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "data['year'] = data['year'].apply(str)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check a sample to see if more cleaning is needed\n",
    "\n",
    "#data.loc[2, 'speech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_for_tdm(text):\n",
    "    '''Remove forward slash, punctuation and numbers'''\n",
    "    text = text.replace(\"\\\\\", \"\")\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean column speech\n",
    "data['speech'] = data.speech.map(lambda x : clean_for_tdm(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1946</td>\n",
       "      <td>a quarter century ago the congress decided tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1976</td>\n",
       "      <td>mr speaker mr vice president members of the  c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>tonight i come not to speak about the state of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002</td>\n",
       "      <td>we last met in an hour of shock and suffering ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>madame speaker mr vice president members of co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                             speech\n",
       "0  1946  a quarter century ago the congress decided tha...\n",
       "1  1976  mr speaker mr vice president members of the  c...\n",
       "2  1990  tonight i come not to speak about the state of...\n",
       "3  2002  we last met in an hour of shock and suffering ...\n",
       "4  2009  madame speaker mr vice president members of co..."
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#data.iloc[2,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DTM (document term matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1946</td>\n",
       "      <td>a quarter century ago the congress decided tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1976</td>\n",
       "      <td>mr speaker mr vice president members of the  c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>tonight i come not to speak about the state of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002</td>\n",
       "      <td>we last met in an hour of shock and suffering ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>madame speaker mr vice president members of co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                             speech\n",
       "0  1946  a quarter century ago the congress decided tha...\n",
       "1  1976  mr speaker mr vice president members of the  c...\n",
       "2  1990  tonight i come not to speak about the state of...\n",
       "3  2002  we last met in an hour of shock and suffering ...\n",
       "4  2009  madame speaker mr vice president members of co..."
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set index to year for DTM\n",
    "#data.set_index('year', inplace = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>abess</th>\n",
       "      <th>abide</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>ably</th>\n",
       "      <th>aboutand</th>\n",
       "      <th>abovementioned</th>\n",
       "      <th>abreast</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youngi</th>\n",
       "      <th>youngmy</th>\n",
       "      <th>youre</th>\n",
       "      <th>youve</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4828 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaa  abess  abide  abilities  ability  able  ably  aboutand  \\\n",
       "0    1      0      1          1        3     4     1         0   \n",
       "1    0      0      0          1        2     0     0         0   \n",
       "2    0      0      0          0        0     0     0         1   \n",
       "3    0      0      0          0        0     0     0         0   \n",
       "4    0      1      0          0        3     4     0         0   \n",
       "\n",
       "   abovementioned  abreast  ...  young  younger  youngest  youngi  youngmy  \\\n",
       "0               1        1  ...      1        0         0       0        0   \n",
       "1               0        0  ...      0        1         1       1        1   \n",
       "2               0        0  ...      2        0         0       0        0   \n",
       "3               0        0  ...      0        1         0       0        0   \n",
       "4               0        0  ...      2        0         0       0        0   \n",
       "\n",
       "   youre  youve  zero  zone  zones  \n",
       "0      0      0     0     2      1  \n",
       "1      0      0     0     0      0  \n",
       "2      2      0     0     0      1  \n",
       "3      0      0     1     0      0  \n",
       "4      0      1     0     0      0  \n",
       "\n",
       "[5 rows x 4828 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "data_cv = cv.fit_transform(data.speech)\n",
    "data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_dtm.index = data.index\n",
    "data_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dtm.to_pickle('pickled_data/dtm.pkl')\n",
    "#pickle.dump(cv, open(\"cv.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Inspecting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abess</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abide</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abilities</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  1  2  3  4\n",
       "aaa        1  0  0  0  0\n",
       "abess      0  0  0  0  1\n",
       "abide      1  0  0  0  0\n",
       "abilities  1  1  0  0  0\n",
       "ability    3  2  0  0  3"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dtm = data_dtm.transpose()\n",
    "data_dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [('dollars', 197),\n",
       "  ('war', 177),\n",
       "  ('year', 166),\n",
       "  ('million', 131),\n",
       "  ('fiscal', 117),\n",
       "  ('expenditures', 112),\n",
       "  ('government', 112),\n",
       "  ('program', 93),\n",
       "  ('united', 89),\n",
       "  ('billion', 79),\n",
       "  ('federal', 68),\n",
       "  ('congress', 67),\n",
       "  ('states', 66),\n",
       "  ('legislation', 60),\n",
       "  ('national', 58),\n",
       "  ('nations', 52),\n",
       "  ('world', 51),\n",
       "  ('estimated', 51),\n",
       "  ('economic', 51),\n",
       "  ('business', 50)],\n",
       " 1: [('federal', 34),\n",
       "  ('year', 25),\n",
       "  ('america', 17),\n",
       "  ('government', 17),\n",
       "  ('people', 16),\n",
       "  ('new', 16),\n",
       "  ('programs', 15),\n",
       "  ('congress', 14),\n",
       "  ('budget', 14),\n",
       "  ('economy', 13),\n",
       "  ('americans', 13),\n",
       "  ('american', 13),\n",
       "  ('world', 12),\n",
       "  ('states', 12),\n",
       "  ('local', 12),\n",
       "  ('help', 12),\n",
       "  ('tax', 12),\n",
       "  ('future', 11),\n",
       "  ('state', 11),\n",
       "  ('know', 10)],\n",
       " 2: [('american', 20),\n",
       "  ('america', 19),\n",
       "  ('world', 19),\n",
       "  ('new', 17),\n",
       "  ('year', 14),\n",
       "  ('time', 14),\n",
       "  ('tonight', 12),\n",
       "  ('future', 11),\n",
       "  ('need', 10),\n",
       "  ('idea', 10),\n",
       "  ('ago', 10),\n",
       "  ('let', 9),\n",
       "  ('people', 9),\n",
       "  ('today', 9),\n",
       "  ('kids', 9),\n",
       "  ('hope', 9),\n",
       "  ('state', 8),\n",
       "  ('capital', 8),\n",
       "  ('change', 8),\n",
       "  ('budget', 8)],\n",
       " 3: [('america', 33),\n",
       "  ('security', 19),\n",
       "  ('world', 16),\n",
       "  ('american', 15),\n",
       "  ('terror', 14),\n",
       "  ('new', 13),\n",
       "  ('good', 13),\n",
       "  ('weapons', 12),\n",
       "  ('people', 12),\n",
       "  ('war', 11),\n",
       "  ('jobs', 11),\n",
       "  ('terrorists', 10),\n",
       "  ('country', 10),\n",
       "  ('freedom', 10),\n",
       "  ('nation', 10),\n",
       "  ('afghanistan', 10),\n",
       "  ('states', 9),\n",
       "  ('terrorist', 9),\n",
       "  ('time', 8),\n",
       "  ('camps', 8)],\n",
       " 4: [('american', 25),\n",
       "  ('economy', 22),\n",
       "  ('know', 22),\n",
       "  ('plan', 21),\n",
       "  ('health', 20),\n",
       "  ('people', 20),\n",
       "  ('new', 20),\n",
       "  ('care', 18),\n",
       "  ('america', 17),\n",
       "  ('years', 15),\n",
       "  ('time', 14),\n",
       "  ('energy', 14),\n",
       "  ('education', 14),\n",
       "  ('budget', 13),\n",
       "  ('jobs', 13),\n",
       "  ('americans', 12),\n",
       "  ('make', 12),\n",
       "  ('country', 12),\n",
       "  ('nation', 11),\n",
       "  ('crisis', 11)]}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the 20 most used words in each speech\n",
    "top_words = {}\n",
    "\n",
    "for c in data_dtm.columns:\n",
    "    top = data_dtm[c].sort_values(ascending=False).head(20)\n",
    "    top_words[c]= list(zip(top.index, top.values))\n",
    "\n",
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "dollars, war, year, million, fiscal, expenditures, government, program, united, billion, federal, congress, states, legislation\n",
      "\n",
      "1\n",
      "federal, year, america, government, people, new, programs, congress, budget, economy, americans, american, world, states\n",
      "\n",
      "2\n",
      "american, america, world, new, year, time, tonight, future, need, idea, ago, let, people, today\n",
      "\n",
      "3\n",
      "america, security, world, american, terror, new, good, weapons, people, war, jobs, terrorists, country, freedom\n",
      "\n",
      "4\n",
      "american, economy, know, plan, health, people, new, care, america, years, time, energy, education, budget\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Print the 15 most used words in each speech, check if some should be added to stopword list,\n",
    "if they are irrelevant for the topic analysis'''\n",
    "for year, t_words in top_words.items():\n",
    "    print(year)\n",
    "    print(', '.join([word for word, count in t_words[0:14]]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dollars',\n",
       " 'war',\n",
       " 'year',\n",
       " 'million',\n",
       " 'fiscal',\n",
       " 'expenditures',\n",
       " 'government',\n",
       " 'program',\n",
       " 'united',\n",
       " 'billion',\n",
       " 'federal',\n",
       " 'congress',\n",
       " 'states',\n",
       " 'legislation',\n",
       " 'national',\n",
       " 'nations',\n",
       " 'world',\n",
       " 'estimated',\n",
       " 'economic',\n",
       " 'business',\n",
       " 'federal',\n",
       " 'year',\n",
       " 'america',\n",
       " 'government',\n",
       " 'people',\n",
       " 'new',\n",
       " 'programs',\n",
       " 'congress',\n",
       " 'budget',\n",
       " 'economy',\n",
       " 'americans',\n",
       " 'american',\n",
       " 'world',\n",
       " 'states',\n",
       " 'local',\n",
       " 'help',\n",
       " 'tax',\n",
       " 'future',\n",
       " 'state',\n",
       " 'know',\n",
       " 'american',\n",
       " 'america',\n",
       " 'world',\n",
       " 'new',\n",
       " 'year',\n",
       " 'time',\n",
       " 'tonight',\n",
       " 'future',\n",
       " 'need',\n",
       " 'idea',\n",
       " 'ago',\n",
       " 'let',\n",
       " 'people',\n",
       " 'today',\n",
       " 'kids',\n",
       " 'hope',\n",
       " 'state',\n",
       " 'capital',\n",
       " 'change',\n",
       " 'budget',\n",
       " 'america',\n",
       " 'security',\n",
       " 'world',\n",
       " 'american',\n",
       " 'terror',\n",
       " 'new',\n",
       " 'good',\n",
       " 'weapons',\n",
       " 'people',\n",
       " 'war',\n",
       " 'jobs',\n",
       " 'terrorists',\n",
       " 'country',\n",
       " 'freedom',\n",
       " 'nation',\n",
       " 'afghanistan',\n",
       " 'states',\n",
       " 'terrorist',\n",
       " 'time',\n",
       " 'camps',\n",
       " 'american',\n",
       " 'economy',\n",
       " 'know',\n",
       " 'plan',\n",
       " 'health',\n",
       " 'people',\n",
       " 'new',\n",
       " 'care',\n",
       " 'america',\n",
       " 'years',\n",
       " 'time',\n",
       " 'energy',\n",
       " 'education',\n",
       " 'budget',\n",
       " 'jobs',\n",
       " 'americans',\n",
       " 'make',\n",
       " 'country',\n",
       " 'nation',\n",
       " 'crisis']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make list of top 20 words in each of the 5 speeches, from top_words dict\n",
    "words = []\n",
    "for year in data_dtm.columns:\n",
    "    top = [word for (word, count) in top_words[year]]\n",
    "    for t in top:\n",
    "        words.append(t)\n",
    "        \n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('world', 4),\n",
       " ('america', 4),\n",
       " ('people', 4),\n",
       " ('new', 4),\n",
       " ('american', 4),\n",
       " ('year', 3),\n",
       " ('states', 3),\n",
       " ('budget', 3),\n",
       " ('time', 3),\n",
       " ('war', 2),\n",
       " ('government', 2),\n",
       " ('federal', 2),\n",
       " ('congress', 2),\n",
       " ('economy', 2),\n",
       " ('americans', 2),\n",
       " ('future', 2),\n",
       " ('state', 2),\n",
       " ('know', 2),\n",
       " ('jobs', 2),\n",
       " ('country', 2),\n",
       " ('nation', 2),\n",
       " ('dollars', 1),\n",
       " ('million', 1),\n",
       " ('fiscal', 1),\n",
       " ('expenditures', 1),\n",
       " ('program', 1),\n",
       " ('united', 1),\n",
       " ('billion', 1),\n",
       " ('legislation', 1),\n",
       " ('national', 1),\n",
       " ('nations', 1),\n",
       " ('estimated', 1),\n",
       " ('economic', 1),\n",
       " ('business', 1),\n",
       " ('programs', 1),\n",
       " ('local', 1),\n",
       " ('help', 1),\n",
       " ('tax', 1),\n",
       " ('tonight', 1),\n",
       " ('need', 1),\n",
       " ('idea', 1),\n",
       " ('ago', 1),\n",
       " ('let', 1),\n",
       " ('today', 1),\n",
       " ('kids', 1),\n",
       " ('hope', 1),\n",
       " ('capital', 1),\n",
       " ('change', 1),\n",
       " ('security', 1),\n",
       " ('terror', 1),\n",
       " ('good', 1),\n",
       " ('weapons', 1),\n",
       " ('terrorists', 1),\n",
       " ('freedom', 1),\n",
       " ('afghanistan', 1),\n",
       " ('terrorist', 1),\n",
       " ('camps', 1),\n",
       " ('plan', 1),\n",
       " ('health', 1),\n",
       " ('care', 1),\n",
       " ('years', 1),\n",
       " ('energy', 1),\n",
       " ('education', 1),\n",
       " ('make', 1),\n",
       " ('crisis', 1)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word and number of speeches it appears in\n",
    "Counter(words).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['world',\n",
       " 'america',\n",
       " 'people',\n",
       " 'new',\n",
       " 'american',\n",
       " 'year',\n",
       " 'states',\n",
       " 'budget',\n",
       " 'time']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''looking at the data, we decide that the most common words are irrelevant if they appear in more than 2 speeches'''\n",
    "add_stop_words = [word for word, count in Counter(words).most_common() if count > 2]\n",
    "add_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update stop word list with the words found above, union is used to avoid duplicates\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for analysis and first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DTM is upated with the new stopwords\n",
    "\n",
    "cv_stop = CountVectorizer(stop_words=stop_words)\n",
    "data_cv = cv_stop.fit_transform(data.speech)\n",
    "data_stop = pd.DataFrame(data_cv.toarray(), columns=cv_stop.get_feature_names())\n",
    "data_stop.index = data.index\n",
    "\n",
    "#data_stop.to_pickle('pickled_data/dtm_stop.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>abess</th>\n",
       "      <th>abide</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>ably</th>\n",
       "      <th>aboutand</th>\n",
       "      <th>abovementioned</th>\n",
       "      <th>abreast</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youngi</th>\n",
       "      <th>youngmy</th>\n",
       "      <th>youre</th>\n",
       "      <th>youve</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4819 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaa  abess  abide  abilities  ability  able  ably  aboutand  \\\n",
       "0    1      0      1          1        3     4     1         0   \n",
       "1    0      0      0          1        2     0     0         0   \n",
       "2    0      0      0          0        0     0     0         1   \n",
       "3    0      0      0          0        0     0     0         0   \n",
       "4    0      1      0          0        3     4     0         0   \n",
       "\n",
       "   abovementioned  abreast  ...  young  younger  youngest  youngi  youngmy  \\\n",
       "0               1        1  ...      1        0         0       0        0   \n",
       "1               0        0  ...      0        1         1       1        1   \n",
       "2               0        0  ...      2        0         0       0        0   \n",
       "3               0        0  ...      0        1         0       0        0   \n",
       "4               0        0  ...      2        0         0       0        0   \n",
       "\n",
       "   youre  youve  zero  zone  zones  \n",
       "0      0      0     0     2      1  \n",
       "1      0      0     0     0      0  \n",
       "2      2      0     0     0      1  \n",
       "3      0      0     1     0      0  \n",
       "4      0      1     0     0      0  \n",
       "\n",
       "[5 rows x 4819 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abess</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abide</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abilities</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  1  2  3  4\n",
       "aaa        1  0  0  0  0\n",
       "abess      0  0  0  0  1\n",
       "abide      1  0  0  0  0\n",
       "abilities  1  1  0  0  0\n",
       "ability    3  2  0  0  3"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm = data_stop.T\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change dtm df, first to sparse matrix and then to gensim corpus\n",
    "\n",
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gensim requires dictionary of the all terms and their respective location in the term-document matrix\n",
    "id2word = dict((v, k) for k, v in cv_stop.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.014*\"dollars\" + 0.012*\"war\" + 0.009*\"million\" + 0.008*\"fiscal\" + 0.008*\"government\" + 0.008*\"expenditures\" + 0.006*\"program\" + 0.006*\"united\" + 0.005*\"billion\" + 0.005*\"federal\"'),\n",
       " (1,\n",
       "  '0.004*\"know\" + 0.004*\"federal\" + 0.004*\"economy\" + 0.004*\"health\" + 0.003*\"americans\" + 0.003*\"congress\" + 0.003*\"jobs\" + 0.003*\"help\" + 0.003*\"future\" + 0.003*\"make\"')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# corpus = TDM and id2word = dict {location : term}\n",
    "'''LDA for 2 topics and 10 passes'''\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"know\" + 0.004*\"health\" + 0.004*\"nation\" + 0.004*\"country\" + 0.004*\"tonight\" + 0.004*\"plan\" + 0.004*\"jobs\" + 0.003*\"economy\" + 0.003*\"need\" + 0.003*\"make\"'),\n",
       " (1,\n",
       "  '0.014*\"dollars\" + 0.013*\"war\" + 0.010*\"million\" + 0.009*\"fiscal\" + 0.008*\"government\" + 0.008*\"expenditures\" + 0.007*\"program\" + 0.006*\"united\" + 0.006*\"billion\" + 0.005*\"federal\"'),\n",
       " (2,\n",
       "  '0.009*\"federal\" + 0.005*\"government\" + 0.004*\"programs\" + 0.004*\"congress\" + 0.003*\"economy\" + 0.003*\"americans\" + 0.003*\"tax\" + 0.003*\"help\" + 0.003*\"local\" + 0.003*\"future\"')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''LDA for 3 topics and 10 passes'''\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.006*\"security\" + 0.005*\"terror\" + 0.004*\"good\" + 0.004*\"weapons\" + 0.004*\"war\" + 0.004*\"jobs\" + 0.003*\"country\" + 0.003*\"nation\" + 0.003*\"freedom\" + 0.003*\"terrorists\"'),\n",
       " (1,\n",
       "  '0.013*\"dollars\" + 0.012*\"war\" + 0.009*\"million\" + 0.008*\"government\" + 0.008*\"fiscal\" + 0.007*\"expenditures\" + 0.007*\"federal\" + 0.006*\"program\" + 0.006*\"united\" + 0.005*\"billion\"'),\n",
       " (2,\n",
       "  '0.006*\"know\" + 0.005*\"health\" + 0.005*\"care\" + 0.004*\"tonight\" + 0.004*\"plan\" + 0.004*\"economy\" + 0.004*\"years\" + 0.004*\"future\" + 0.003*\"need\" + 0.003*\"nation\"'),\n",
       " (3,\n",
       "  '0.000*\"dollars\" + 0.000*\"war\" + 0.000*\"government\" + 0.000*\"million\" + 0.000*\"united\" + 0.000*\"billion\" + 0.000*\"congress\" + 0.000*\"fiscal\" + 0.000*\"program\" + 0.000*\"federal\"')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''LDA for 4 topics and 10 passes'''\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As the results include several words that are irrelevant to possible topics, we try and narrow the search by only including nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that selects nouns only and return those as a string, details see: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "\n",
    "def nouns(text):\n",
    "    '''tokenize a string and return only the nouns.'''\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)] \n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>abess</th>\n",
       "      <th>abide</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>ably</th>\n",
       "      <th>aboutand</th>\n",
       "      <th>abovementioned</th>\n",
       "      <th>abreast</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youngi</th>\n",
       "      <th>youngmy</th>\n",
       "      <th>youre</th>\n",
       "      <th>youve</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4828 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aaa  abess  abide  abilities  ability  able  ably  aboutand  \\\n",
       "year                                                                \n",
       "1946    1      0      1          1        3     4     1         0   \n",
       "1976    0      0      0          1        2     0     0         0   \n",
       "1990    0      0      0          0        0     0     0         1   \n",
       "2002    0      0      0          0        0     0     0         0   \n",
       "2009    0      1      0          0        3     4     0         0   \n",
       "\n",
       "      abovementioned  abreast  ...  young  younger  youngest  youngi  youngmy  \\\n",
       "year                           ...                                              \n",
       "1946               1        1  ...      1        0         0       0        0   \n",
       "1976               0        0  ...      0        1         1       1        1   \n",
       "1990               0        0  ...      2        0         0       0        0   \n",
       "2002               0        0  ...      0        1         0       0        0   \n",
       "2009               0        0  ...      2        0         0       0        0   \n",
       "\n",
       "      youre  youve  zero  zone  zones  \n",
       "year                                   \n",
       "1946      0      0     0     2      1  \n",
       "1976      0      0     0     0      0  \n",
       "1990      2      0     0     0      1  \n",
       "2002      0      0     1     0      0  \n",
       "2009      0      1     0     0      0  \n",
       "\n",
       "[5 rows x 4828 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = pd.read_pickle('pickled_data/dtm.pkl')\n",
    "data_clean.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quarter century congress programs departments ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mr speaker vice president members congress gue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tonight i state government initiative year lin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hour shock suffering months nation victims yor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>madame speaker vice president members congress...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              speech\n",
       "0  quarter century congress programs departments ...\n",
       "1  mr speaker vice president members congress gue...\n",
       "2  tonight i state government initiative year lin...\n",
       "3  hour shock suffering months nation victims yor...\n",
       "4  madame speaker vice president members congress..."
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nouns = pd.DataFrame(data.speech.apply(nouns))\n",
    "data_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>aboutand</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absence</th>\n",
       "      <th>absorption</th>\n",
       "      <th>abundance</th>\n",
       "      <th>abuse</th>\n",
       "      <th>acceptance</th>\n",
       "      <th>...</th>\n",
       "      <th>years</th>\n",
       "      <th>yearswe</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yield</th>\n",
       "      <th>york</th>\n",
       "      <th>youngmy</th>\n",
       "      <th>youre</th>\n",
       "      <th>youve</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2550 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaa  abilities  ability  aboutand  abroad  absence  absorption  abundance  \\\n",
       "0    1          1        3         0       1        0           1          0   \n",
       "1    0          1        2         0       0        0           0          1   \n",
       "2    0          0        0         1       0        0           0          0   \n",
       "3    0          0        0         0       0        0           0          0   \n",
       "4    0          0        3         0       0        1           0          0   \n",
       "\n",
       "   abuse  acceptance  ...  years  yearswe  yesterday  yield  york  youngmy  \\\n",
       "0      0           0  ...     41        0          0      1     1        0   \n",
       "1      1           0  ...      8        1          0      0     0        1   \n",
       "2      0           0  ...      6        0          0      0     0        0   \n",
       "3      0           0  ...      2        0          0      0     2        0   \n",
       "4      1           1  ...     15        0          1      1     0        0   \n",
       "\n",
       "   youre  youve  zone  zones  \n",
       "0      0      0     1      1  \n",
       "1      0      0     0      0  \n",
       "2      1      0     0      0  \n",
       "3      0      0     0      0  \n",
       "4      0      1     0      0  \n",
       "\n",
       "[5 rows x 2550 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recreate a document-term matrix with only nouns\n",
    "cvn = CountVectorizer(stop_words=stop_words)\n",
    "data_cvn = cvn.fit_transform(data_nouns.speech)\n",
    "data_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names())\n",
    "data_dtmn.index = data_nouns.index\n",
    "data_dtmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusn = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmn.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordn = dict((v, k) for k, v in cvn.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.008*\"economy\" + 0.007*\"health\" + 0.007*\"jobs\" + 0.007*\"americans\" + 0.006*\"security\" + 0.006*\"congress\" + 0.006*\"government\" + 0.006*\"tax\" + 0.006*\"care\" + 0.006*\"country\"'),\n",
       " (1,\n",
       "  '0.023*\"dollars\" + 0.020*\"war\" + 0.013*\"government\" + 0.011*\"program\" + 0.011*\"expenditures\" + 0.008*\"congress\" + 0.007*\"legislation\" + 0.006*\"nations\" + 0.006*\"production\" + 0.006*\"business\"')]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''LDA for 2 topics, 10 passes and nouns only'''\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=2, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.009*\"economy\" + 0.008*\"jobs\" + 0.008*\"health\" + 0.007*\"americans\" + 0.007*\"security\" + 0.007*\"congress\" + 0.007*\"tax\" + 0.007*\"government\" + 0.006*\"country\" + 0.006*\"care\"'),\n",
       " (1,\n",
       "  '0.026*\"dollars\" + 0.023*\"war\" + 0.015*\"government\" + 0.012*\"expenditures\" + 0.012*\"program\" + 0.009*\"congress\" + 0.008*\"legislation\" + 0.007*\"nations\" + 0.007*\"business\" + 0.007*\"production\"'),\n",
       " (2,\n",
       "  '0.006*\"idea\" + 0.005*\"future\" + 0.005*\"today\" + 0.005*\"kids\" + 0.005*\"state\" + 0.005*\"change\" + 0.004*\"nation\" + 0.004*\"capital\" + 0.004*\"home\" + 0.004*\"europe\"')]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=3, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.008*\"health\" + 0.007*\"nation\" + 0.007*\"country\" + 0.007*\"jobs\" + 0.007*\"economy\" + 0.006*\"care\" + 0.006*\"plan\" + 0.006*\"years\" + 0.006*\"security\" + 0.006*\"americans\"'),\n",
       " (1,\n",
       "  '0.027*\"dollars\" + 0.024*\"war\" + 0.015*\"government\" + 0.013*\"expenditures\" + 0.013*\"program\" + 0.009*\"congress\" + 0.008*\"legislation\" + 0.007*\"nations\" + 0.007*\"production\" + 0.007*\"business\"'),\n",
       " (2,\n",
       "  '0.001*\"dollars\" + 0.001*\"war\" + 0.001*\"government\" + 0.001*\"expenditures\" + 0.001*\"program\" + 0.001*\"congress\" + 0.001*\"programs\" + 0.001*\"years\" + 0.001*\"nations\" + 0.001*\"business\"'),\n",
       " (3,\n",
       "  '0.010*\"government\" + 0.009*\"programs\" + 0.007*\"congress\" + 0.007*\"economy\" + 0.007*\"americans\" + 0.007*\"tax\" + 0.006*\"state\" + 0.006*\"growth\" + 0.005*\"energy\" + 0.005*\"jobs\"')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=4, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using nouns AND adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that returns nouns and adjectives from a text string\n",
    "def nouns_adj(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns and adjectives.'''\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)] \n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mr speaker mr vice president members congress guestsas bicentennial america youngest nations recorded history forefathers shores men women planet better life familiesin mans long upward march savagery years christian calendar years jewish reckoningthere many deep valleys many bright peaksone peak highest ranges human history example shines forth people abundance share good life freedom union promise justice opportunity citizen union united states americawe paradise earth perfection minute yearswe many roots many branches americans generations deeds other homeland refuge shores unison i proud america i proud americanlife little better children i i life father mother i better children hands brains voice vote america exists conditions people ideas practical reality best times much translation best intentions recent past sound most history great things ageold problems overconfident abilities policeman indulgent parent homewe thought country massive national programs programs things rush great deeds sound principles restraint rights individuals economic system huge unprecedented growth federal expenditures borrowing honest ourselves much programs emphasis defense domestic problems adversaries massive buildup armsthe time different approach new realism true great principles nation new balance economya balance sound active government vigorous healthy economy new jobs priceswe new balance relationship individual governmenta balance favors greater individual freedom selfreliancewe new balance system federalisma balance favors greater responsibility freedom leaders state local governmentswe new balance spending domestic programs defensea balance obligation needy security world hostile honest american people more genius america incredible ability lives citizens unique combination governmental free citizen activityhistory experience tells moral progress comfortable complacent times trial confusion tom paine troubled americans times mens souls harder conflict glorious triumphjust year i state union good tonight i state union many ways lot betterbut good enoughto paraphrase tom paine year summer soldiers sum shine patriots year fears alarms dire forecastsmost wont happenas year rancor bitterness political misdeeds past longest divisive war history unhappy conclusion many end foreign war men machines beginning domestic war recrimination reprisal friends adversaries america nerve economy inflationinflation worse recession decades same time americans big institutions confidence big government big business big labor big education others ours troubled landand year hard decisions difficult compromises new realism something important america needed measure common sense steadfastness selfdisciplineamericans panic demand instant useless cures sectors people difficult problems restraint responsibility worthy great separate pieces progress subtract setbacks sum total new direction direction months right directionit right direction revolutionary american concept free society making public policy successful more government full partnership branches levels government private institutions individual citizenscommon sense steady state economy last january most things january things betterthe worst recession world war ii april best news past year doubledigit inflation percent higher worstunemployment hightoday americans bottom recession years people lets many americans changes daily lives prices fast fear unemploymentwe nation more more jobs year economy jobs americans lot more jobs youngmy objective sound economic growth inflationwe recent experience inflation other worthy purpose coldfor many americans way healthy noninflationary economy apparent government spending much stop borrowing money more money private hands good cost living cost governmentin past decade federal budget average rate percent year budget i wednesday cuts rate growth half i promise budget next fiscal year fact billionby growth federal spending additional tax cuts people taxes decisionmaking power own liveslast month i legislation tax reductions first months year effective july taxpayers tax cut more congress decembermy broader tax reduction family year takehome pay hardworking americans middle kind extra cashmy recommendations firm restraint growth federal spending greater tax reduction simple straightforward dollar growth federal budget added dollar federal tax reductionwe balanced budget courage wisdom growth federal spendingone test healthy economy job american governmentour kind governmentcannot create many jobs federal government conditions incentives private business industry more jobsfive jobs country private business industry common sense place more jobs faster i real rewarding permanent jobsto american people greater incentives future tax proposals major step direction proposals congress enact changes federal tax laws plant expansion purchase new equipment recommendations jobcreation tax incentive areas unemployment rate percent legislation earliest possible strict budget total i year i additional housing assistance families programs housing opportunities construction help house moderate lowincome familieswe disappointing year housing industry lower interest rates available mortgage money healthy recovery necessary condition healthy economy petty tyranny massive government regulation millions hours billions taxpayers consumers dollars bureaucratic redtape american farmer americans millions shackles government controlnow reforms other key areas economy airlines railroads financial institutions concrete plans areas industry competition prices consumerthis administration addition federal antitrust laws same look americas future sustained growth more jobs assured supply energy economy domestic production oil gas dependence foreign oil high prices great jobs dollars own economy rate year americanlast month i compromise national energy bill part comprehensive energy independence program legislation complete answer energy independence start right directioni congress remainder energy proposals america invulnerable foreign oil cartelmy proposals domestic natural gas shortages production federal petroleum reserves effective conservation revitalization railroads expansion urban transportation systems cleaner energy vast coal resources expedite clean safe nuclear power production new national energy independence authority vital energy investment development technology energy sun earth future generationsalso i sake future generations family farm small business strengthen america stability economy i estate tax changes family businesses family farms generation generation taxesi propose tax changes people americas future own plan moderateincome families income tax benefits longterm investments common stock american companiesthe federal government national needsfor future generationshospital medical services america best world cost serious extended illness familys lifetime savings health costs deep concern powerful force cost burden catastrophic illness few society fear familyi catastrophic health insurance everybody medicare added protection fees shortterm care nobody age more year covered hospital nursing home care more years doctor billswe national health insurance full coverage americans experience other countries questions quality cost such plans i day private health insurance system more middleincome families quality health services prices catastrophic illnessesusing resources available i medicare other federal health programs protectionolder people poor states local governments better health care poor i federal programs medicaid single federal grantfunds states new formula larger share federal money states larger share lowincome familiesi further steps quality medical hospital care forcesnow social security federal social security system people lives vital part economic system value debatable budget fiscal year i full costofliving increases social security benefits yearbut i integrity social security trust fund retired count source retirement income younger workers deductions rise wonder future challenge head simple arithmetic warns social security trust fund trouble sure fund much security old youngi threetenths percent increase employer employee social security taxes effective january covered employee less extra dollar week integrity trust fundas economy responsibility temporary cushion unemployed request congress extensions expansions unemployment insurance jobless programs fiscal year budget i funds proven job training employment opportunity programs millions other americanscompassion sense communitytwo americas greatest strengths history care neighbors care host federal programs field generosity peoplebut everyone government levels job many welfare programs inequitable invite abuse many welfare programs problems worse resources many truly needycomplex welfare programs overnight welfare laps states local taxpayers private charities right time massive sweeping changes recessionnevertheless plenty improvements i congress presidential authority rules eligibility benefitslast year i long overdue reform food stamp program year lets food stamps need lets life property citizen home responsibility public officials job local state law enforcement authoritiesamericans thought federal police force repugnant i proper ways domestic tranquility constitution charges recommendations violent crime congress last june strong emphasis innocent victims crime criminal more crimes prison lawabiding citizens effective punishment swift certaintoo criminals prison conviction streets judges reluctant convicted criminals prison inadequate facilities problem federal level new budget construction new federal facilitiesto speed federal justice i increase year united states attorneys federal crimes reinforcement number united states marshals additional federal judges judicial conferenceanother major threat americans person property criminal handgun way criminal use guns guns citizen mandatory sentences crimes gun harder cheap guns criminal purposes gun enforcement highcrime areasmy budget additional federal agents largest metropolitan highcrime areas local authorities criminals handgunsthe sale hard drugs increase agencies federal government law enforcement efforts drugs i glad federal agents more heroin country president i leaders mexico colombia turkey greater efforts governments production shipment hard drugsi months congress enact mandatory sentences persons federal crimes sale hard drugs hard drugs spirit body usersit unrealistic hope federal government neighborhood crime constitution greatest responsibility crime state local authorities frontline fighters war crimethere definite ways federal government new budget congress next years state local governments safety property citizensas president i strict enforcement federal laws example support leadershipto help state local authorities laws victims crime domestic year extension revenue legislation state local units government solve problems home program effective federal government officials congress year state local units government programs local health care program reforms separate federal programs flexible federal dollar grants states cities local agencies such important areas education child nutrition social services flexible system job protection lives property americans foreign enemies primary responsibilities presidentin world instant communications intercontinental ballistic missiles world economy global interdependent relations other nations important lives americansamerica unique role world day independence years end world war ii heavy responsibility stable world order hope human progresstoday state foreign policy sound strong peace i power military forces capable ready military power equal i principal alliances industrial democracies atlantic community japan more solida agreement strategic arms race improving relationship china worlds populous nationthe key elements peace nations middle east traditional friendships latin america africa asia continuewe role leadership serious hopeful dialog industrial world worldwe significant reform international monetary systemwe proud country areas i american people arethe american people much terrible mistakes evil deeds misguided purposes american people betterthe truth worlds greatest democracy symbol mans aspiration liberty wellbeing embodiment hope progressi time nation course responsibility right lesson past mistakes duty greater duty future worlds troubles awaythe american people strong effective international defense policies constitutional system policies consultation accommodation president congress final analysis framers constitution hard experience foreign relations united states strong central direction flexibility action responsibility presidenti pledge american people policies secure peaceful world i congress endwe future friends such angola limited ways capacity short military interventionsome hasty actions congress past yearmost respect view minds allies adversariesa strong defense posture weight values views international negotiations vigor alliances efforts settlements international conflicts position strength balanced agreement growth nuclear arms balanced agreement interests threat nuclear confrontationthe defense budget i congress fiscal year essential increase current year real growth power years defense budget cost allvolunteer forcewe economies efficiency military forces budget i necessity american strength real world conflict rivalry persist world united states intelligence capabilities best worldthe crippling foreign intelligence services danger american involvement direct conflict adversaries new adventures own ability events events short military action effective intelligence capability united states stands near future i actions intelligence community ask positive cooperation time sensationalism effective responsible responsive intelligence capabilitytonight i problems home i policies challenge third century i doubt union better stronger more individual freedom year years generation forefathers challenges own time common sense purpose conviction true constitution ideals future better pasti see today threshold bicentennial adversity new look nation america resurgent certain life better children strength megatons riches inflationi see united states america perfect union government serves people speeches good bad yours mine hard work hard decisions courage common sensei many presidential speeches words best dwight d eisenhower america good great president america great goodpresident eisenhower poor religious home heart america simple words president lincolns eloquent testament right turn silent image george washington prayer valley magic memories generations americans inscription many times god hearts bicentennial'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_nouns_adj = pd.DataFrame(data.speech.apply(nouns_adj))\n",
    "data_nouns_adj.speech[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboutand</th>\n",
       "      <th>abovementioned</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absence</th>\n",
       "      <th>absorption</th>\n",
       "      <th>abundance</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youngi</th>\n",
       "      <th>youngmy</th>\n",
       "      <th>youre</th>\n",
       "      <th>youve</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3379 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaa  abilities  ability  able  aboutand  abovementioned  abroad  absence  \\\n",
       "0    1          1        3     4         0               1       1        0   \n",
       "1    0          1        2     0         0               0       0        0   \n",
       "2    0          0        0     0         1               0       0        0   \n",
       "3    0          0        0     0         0               0       0        0   \n",
       "4    0          0        3     4         0               0       0        1   \n",
       "\n",
       "   absorption  abundance  ...  york  young  younger  youngest  youngi  \\\n",
       "0           1          1  ...     1      1        0         0       0   \n",
       "1           0          1  ...     0      0        1         1       1   \n",
       "2           0          0  ...     0      2        0         0       0   \n",
       "3           0          0  ...     2      0        1         0       0   \n",
       "4           0          0  ...     0      2        0         0       0   \n",
       "\n",
       "   youngmy  youre  youve  zone  zones  \n",
       "0        0      0      0     1      1  \n",
       "1        1      0      0     0      0  \n",
       "2        0      1      0     0      0  \n",
       "3        0      0      0     0      0  \n",
       "4        0      0      1     0      0  \n",
       "\n",
       "[5 rows x 3379 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recreate a document-term matrix with nouns AND adjectives\n",
    "\n",
    "cvna = CountVectorizer(stop_words=stop_words)\n",
    "data_cvna = cvna.fit_transform(data_nouns_adj.speech)\n",
    "data_dtmna = pd.DataFrame(data_cvna.toarray(), columns=cvna.get_feature_names())\n",
    "data_dtmna.index = data_nouns_adj.index\n",
    "data_dtmna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmna.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordna = dict((v, k) for k, v in cvna.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.006*\"federal\" + 0.005*\"economy\" + 0.005*\"health\" + 0.005*\"jobs\" + 0.005*\"americans\" + 0.005*\"future\" + 0.004*\"congress\" + 0.004*\"nation\" + 0.004*\"country\" + 0.004*\"government\"'),\n",
       " (1,\n",
       "  '0.018*\"dollars\" + 0.016*\"war\" + 0.011*\"fiscal\" + 0.010*\"government\" + 0.009*\"expenditures\" + 0.009*\"program\" + 0.008*\"united\" + 0.006*\"federal\" + 0.006*\"congress\" + 0.006*\"legislation\"')]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#as above, 2 topics and 10 passes\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=2, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.006*\"health\" + 0.006*\"jobs\" + 0.006*\"nation\" + 0.005*\"country\" + 0.005*\"economy\" + 0.005*\"care\" + 0.005*\"americans\" + 0.005*\"plan\" + 0.005*\"security\" + 0.005*\"years\"'),\n",
       " (1,\n",
       "  '0.001*\"war\" + 0.001*\"dollars\" + 0.001*\"jobs\" + 0.001*\"health\" + 0.001*\"federal\" + 0.001*\"government\" + 0.001*\"congress\" + 0.001*\"united\" + 0.001*\"fiscal\" + 0.001*\"economy\"'),\n",
       " (2,\n",
       "  '0.017*\"dollars\" + 0.016*\"war\" + 0.011*\"government\" + 0.010*\"fiscal\" + 0.009*\"federal\" + 0.008*\"program\" + 0.008*\"united\" + 0.008*\"expenditures\" + 0.007*\"congress\" + 0.006*\"legislation\"')]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 topics, 10 passes\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=3, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.001*\"war\" + 0.001*\"dollars\" + 0.000*\"government\" + 0.000*\"fiscal\" + 0.000*\"program\" + 0.000*\"federal\" + 0.000*\"united\" + 0.000*\"security\" + 0.000*\"nation\" + 0.000*\"great\"'),\n",
       " (1,\n",
       "  '0.017*\"dollars\" + 0.016*\"war\" + 0.011*\"government\" + 0.011*\"fiscal\" + 0.009*\"federal\" + 0.008*\"program\" + 0.008*\"united\" + 0.008*\"expenditures\" + 0.007*\"congress\" + 0.006*\"legislation\"'),\n",
       " (2,\n",
       "  '0.007*\"jobs\" + 0.007*\"economy\" + 0.007*\"health\" + 0.006*\"plan\" + 0.006*\"security\" + 0.006*\"country\" + 0.006*\"nation\" + 0.006*\"americans\" + 0.005*\"care\" + 0.005*\"energy\"'),\n",
       " (3,\n",
       "  '0.006*\"future\" + 0.005*\"idea\" + 0.005*\"tonight\" + 0.005*\"today\" + 0.005*\"kids\" + 0.004*\"state\" + 0.004*\"free\" + 0.004*\"capital\" + 0.004*\"change\" + 0.004*\"nation\"')]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4 topics, 10 passes\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['speech'], dtype='object')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nouns_adj.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "RangeIndex(start=0, stop=5, step=1)\n",
      "0\n",
      "<class 'int'>\n",
      "1\n",
      "<class 'int'>\n",
      "2\n",
      "<class 'int'>\n",
      "3\n",
      "<class 'int'>\n",
      "4\n",
      "<class 'int'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-be034a6941b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus_transformed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-118-be034a6941b5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus_transformed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 1)"
     ]
    }
   ],
   "source": [
    "# which topics of the 4 lists found, are in which speech (year)\n",
    "corpus_transformed = ldana[corpusna]\n",
    "print(len(corpus_transformed))\n",
    "print(data_dtmna.index)\n",
    "for x in data_dtmna.index:\n",
    "    print(x)\n",
    "    print(type(x))\n",
    "list(zip([a for [(a,b)] in corpus_transformed], data.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Word Clouds for speeches from 5 significant years\n",
    "### 1946: End of WW2, 1976: End of Vietnam war, 1990: End of the cold war, 2002: Following 9/11, 2009: Global fin.crisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_st = pd.read_pickle('pickled_data/data_first_clean.pkl')\n",
    "data_st.drop(['President', 'Party','speech', 'first_clean_tokenized'], axis=1, inplace = True)\n",
    "data_st = data_st.rename({'first_clean' : 'speech'}, axis=1)\n",
    "#Significant years: 1946, end of ww2, 1976 end of Vietnam war, 1990 end of cold war, 2002 9/11, 2009 glob fin crisis\n",
    "years = [1946, 1976, 1990, 2002, 2009]\n",
    "\n",
    "data_st = data_st.loc[data_st['year'].isin(years)]\n",
    "data_st = data_st.reset_index(drop=True)\n",
    "\n",
    "data_st['year'] = data_st.year.astype('str')\n",
    "\n",
    "data_st.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dict for plotting and alterative analysis below\n",
    "speech_dict = dict(zip(data_st.year, data_st.speech))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make wordcloud for each of the 5 speeches\n",
    "stop_words = text.ENGLISH_STOP_WORDS\n",
    "\n",
    "wc = WordCloud(stopwords=stop_words, background_color=\"black\", colormap=\"Dark2\",\n",
    "               max_font_size=150, random_state=42)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "\n",
    "for key, value in speech_dict.items():\n",
    "    wc.generate(value)\n",
    "    \n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(key)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As an experiment, we try the prelearned model from: https://huggingface.co/MoritzLaurer/policy-distilbert-7d on the same 5 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_policy(text):\n",
    "    model_name = \"MoritzLaurer/policy-distilbert-7d\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    input = tokenizer(text, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    output = model(input[\"input_ids\"])\n",
    "    prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "\n",
    "    label_names = [\"external relations\", \"freedom and democracy\",\n",
    "               \"political system\", \"economy\", \"welfare and quality of life\",\n",
    "               \"fabric of society\", \"social groups\"]\n",
    "    prediction = {name: round(float(pred) * 100, 1) for pred, name in\n",
    "              zip(prediction, label_names)}\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in speech_dict.items():\n",
    "    print('Year: ', x)\n",
    "    print(ml_policy(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
